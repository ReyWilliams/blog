<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Rey's Corner | Blog</title><link href="https://github.com/ReyWilliams/blog/blob/main/" rel="alternate"></link><link href="https://github.com/ReyWilliams/blog/blob/main/feeds/all.atom.xml" rel="self"></link><id>https://github.com/ReyWilliams/blog/blob/main/</id><updated>2024-03-20T17:24:00-07:00</updated><entry><title>Sound Detection/Analysis for Firearm Safety Solutions</title><link href="https://github.com/ReyWilliams/blog/blob/main/sound-detectionanalysis-for-firearm-safety-solutions.html" rel="alternate"></link><published>2024-03-20T17:24:00-07:00</published><updated>2024-03-20T17:24:00-07:00</updated><author><name>Rey Williams</name></author><id>tag:github.com,2024-03-20:/ReyWilliams/blog/blob/main/sound-detectionanalysis-for-firearm-safety-solutions.html</id><summary type="html">&lt;h1&gt;Intro&lt;/h1&gt;
&lt;p&gt;Much of the functionality behind this is described in this Amazon machine learning write-up &lt;a href="https://aws.amazon.com/blogs/machine-learning/detect-audio-events-with-amazon-rekognition/"&gt;here&lt;/a&gt;. This solution aims to describe an IoT sound detection/analysis using machine learning for use cases regarding firearm safety and alerting. &lt;/p&gt;
&lt;h1&gt;How Do We Capture Sound?&lt;/h1&gt;
&lt;p&gt;We can leverage a small IoT device-like setup ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Intro&lt;/h1&gt;
&lt;p&gt;Much of the functionality behind this is described in this Amazon machine learning write-up &lt;a href="https://aws.amazon.com/blogs/machine-learning/detect-audio-events-with-amazon-rekognition/"&gt;here&lt;/a&gt;. This solution aims to describe an IoT sound detection/analysis using machine learning for use cases regarding firearm safety and alerting. &lt;/p&gt;
&lt;h1&gt;How Do We Capture Sound?&lt;/h1&gt;
&lt;p&gt;We can leverage a small IoT device-like setup using something like a &lt;a href="https://www.raspberrypi.com/products/raspberry-pi-pico/"&gt;Raspberry Pi Pico&lt;/a&gt; or &lt;a href="https://www.raspberrypi.com/products/raspberry-pi-zero/"&gt;Zero&lt;/a&gt; (or &lt;a href="https://www.ti.com/microcontrollers-mcus-processors/msp430-microcontrollers/overview.html"&gt;MSP430&lt;/a&gt;) which would allow us to run a small Python Script to capture audio and eventually convert them to spectrograms that could then be used for image analysis and labeling. &lt;/p&gt;
&lt;p&gt;The IoT devices alone would not allow us to capture audio so we would have to pair this with some other solution that would allow us to do so. I took a look at a few Adafruit options such as the &lt;a href="https://www.adafruit.com/product/3492"&gt;PDM MEMS Microphone&lt;/a&gt;, the &lt;a href="https://www.adafruit.com/product/3421"&gt;I2S MEMS Microphone&lt;/a&gt;, or the &lt;a href="https://www.adafruit.com/product/1063?gad_source=1&amp;amp;gclid=CjwKCAjwkuqvBhAQEiwA65XxQHe3jAjqpU0v_XDNDbXJCrdvrsYmrcYeFRL4VcEjmexbikw-BFcHUhoCxhkQAvD_BwE"&gt;Electret Microphone Amplifier (w/ Adjustable Gain)&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;The Case for the Electret Microphone&lt;/h2&gt;
&lt;p&gt;The electret microphone would be great as it is best used for ‚Äúprojects such as voice changers, audio recording/sampling, and audio-reactive projects that use FFT‚Äù but we would need to use something like an Arduino or microchip to convert the analog signal to a digital value if an RPI Pico is not used - the Pico uses the &lt;a href="https://datasheets.raspberrypi.com/rp2040/rp2040-datasheet.pdf"&gt;RP2040&lt;/a&gt; MCU which has a 4 channel Analog-to-Digital Converter (ADC). Something like a &lt;a href="https://www.microchip.com/en-us/product/mcp3008"&gt;MCP3008&lt;/a&gt;¬†10-bit ADC could be used to do so. The MCP3008 ‚Äúcombines high performance and low power consumption in a small package, making it ideal for embedded control applications.‚Äú &lt;/p&gt;
&lt;h2&gt;The Case for the PDM Microphone&lt;/h2&gt;
&lt;p&gt;If the electret microphone adds too much additional complexity, the PDM microphone could be used as it provides an analog output natively. On this microphone, as the name implies, the ‚Äúdigital interface is a very simplistic¬†&lt;strong&gt;p&lt;/strong&gt;ulse¬†&lt;strong&gt;d&lt;/strong&gt;ensity¬†&lt;strong&gt;m&lt;/strong&gt;odulation output.‚Äù The product page notes ‚Äúit's digital but its¬†&lt;em&gt;not&lt;/em&gt;¬†PWM and it's¬†&lt;em&gt;not&lt;/em&gt;¬†I2S.‚Äù There is an example implementation of a microphone using an RPi Pico and a PDM &lt;a href="https://www.hackster.io/sandeep-mistry/create-a-usb-microphone-with-the-raspberry-pi-pico-cc9bd5"&gt;here&lt;/a&gt;. &lt;/p&gt;
&lt;h2&gt;The Case for the I2S Microphone&lt;/h2&gt;
&lt;p&gt;The other options sound great until you realize that an ADC like the MCP3008 is not suitable (though it is possible) for recording sound due to the sampling that needs to happen. Internet forums (which of course are &lt;em&gt;always&lt;/em&gt; a source of truth) note that an I2C microphone would be ideal as all PI‚Äôs have a I2S interface that you can make use of (forum posts I reviewed &lt;a href="https://forums.raspberrypi.com/viewtopic.php?t=353806"&gt;here&lt;/a&gt; and &lt;a href="https://forums.raspberrypi.com/viewtopic.php?p=1185062&amp;amp;hilit=record+audio+from+analog+microphone#p1185062"&gt;here&lt;/a&gt;). The I2S mic describes itself as a ‚Äúsmall, low-cost MEMS mic with a range of about 50Hz - 15KHz, good for just about all general audio recording/detection‚Äù which sounds pretty ideal for the use case of sound detection/analysis. There is a &lt;a href="https://learn.adafruit.com/adafruit-i2s-mems-microphone-breakout/raspberry-pi-wiring-test"&gt;write-up on the Adafruit website&lt;/a&gt; that details a setup of using this I2S microphone for both stereo and mono audio capture using a &lt;a href="https://raw.githubusercontent.com/adafruit/Raspberry-Pi-Installer-Scripts/master/i2smic.py"&gt;script&lt;/a&gt;. A lot of the groundwork is done here if this route is taken&lt;/p&gt;
&lt;h2&gt;PDM, PWM, I2S, and Analog‚Ä¶What?&lt;/h2&gt;
&lt;p&gt;I too had to look up these terms, use a bit of AI, and understand what the tradeoffs and differences are and I will share these below. &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° TLDR: analog is king but our other microphones can be ideal.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;Analog&lt;/h3&gt;
&lt;p&gt;This is the natural way sound exists in the real world. It's a continuous signal where the voltage of an electrical signal constantly changes to represent the pressure waves of sound. See this sample image from the PDM microphone &lt;a href="https://learn.adafruit.com/adafruit-pdm-microphone-breakout/"&gt;product page&lt;/a&gt; that denotes a comparison between PDM and analog sine waves.&lt;/p&gt;
&lt;p&gt;&lt;img alt="wav" src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/Pulse_density_modulation.svg/600px-Pulse_density_modulation.svg.png"&gt;&lt;/p&gt;
&lt;h3&gt;PDM (Pulse Density Modulation)&lt;/h3&gt;
&lt;p&gt;This is a digital way to represent an analog audio signal using only one bit - so good ol‚Äô 1‚Äôs and 0‚Äôs. A high density of pulses (1s) represents a high volume, and a low density of pulses (0‚Äôs) represents a low volume. PDM requires a high sampling rate (millions of times per second) to accurately represent the analog signal.&lt;/p&gt;
&lt;h3&gt;I2S (Inter-IC Sound)&lt;/h3&gt;
&lt;p&gt;This is a digital serial interface commonly used to transmit audio data between integrated circuits (ICs) like microchips; it uses multiple bits to represent the audio signal and thus provides higher fidelity than PDM.&lt;/p&gt;
&lt;h3&gt;PWM (Pulse Width Modulation)&lt;/h3&gt;
&lt;p&gt;PWM is not only for audio and it‚Äôs a similar concept used for controlling the intensity of LEDs or the speed of motors. In this concept, a digital signal with a fixed pulse rate is used, but the width of each pulse is varied to represent the desired intensity or speed.&lt;/p&gt;
&lt;h1&gt;What Should Be Done Once Sound is Captured?&lt;/h1&gt;
&lt;p&gt;If we follow the I2S approach and do some tinkering to use a &lt;a href="https://learn.adafruit.com/adafruit-i2s-mems-microphone-breakout/raspberry-pi-wiring-test"&gt;cron job&lt;/a&gt; or the link to (at set intervals) capture a wav file then we can continue on with the &lt;a href="https://aws.amazon.com/blogs/machine-learning/detect-audio-events-with-amazon-rekognition/"&gt;AWS approach&lt;/a&gt; where we would capture those files, upload those files to S3 and then move on to detect audio events using the sound‚Äôs converted spectrogram image and doing analysis that way. &lt;/p&gt;
&lt;p&gt;We would need to follow the &lt;a href="https://github.com/aws-samples/using-rekognition-to-detect-sounds?tab=readme-ov-file#building-a-training-and-validation-data-set"&gt;guide/sample here&lt;/a&gt; (make note of the licenses - small read-up for licensing &lt;a href="https://redpalm.co.uk/importance-of-software-licensing/"&gt;here&lt;/a&gt;) and actually do sample testing with gunshot sounds to really see what spectorgram would be ideal. The guide notes that during the building of the training and validation data set:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Each resulting sound is then converted into a set of different types of spectrogram images. This variety of spectrograms (including Mel, Harmonic, and others) can be tested to determine which spectrogram type works best with your data set.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1&gt;Diagram (WIP)&lt;/h1&gt;
&lt;p&gt;Please use the site footer to switch to light mode and better read the diagram labels.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Diagram" src="https://raw.githubusercontent.com/ReyWilliams/blog/writing/content/images/Sound%20Stream.drawio.svg"&gt;&lt;/p&gt;</content><category term="Research"></category></entry><entry><title>My First Blog Post!</title><link href="https://github.com/ReyWilliams/blog/blob/main/my-first-blog-post.html" rel="alternate"></link><published>2024-03-10T12:24:00-07:00</published><updated>2024-03-10T12:24:00-07:00</updated><author><name>Rey Williams</name></author><id>tag:github.com,2024-03-10:/ReyWilliams/blog/blob/main/my-first-blog-post.html</id><summary type="html">&lt;h1&gt;The beginning!&lt;/h1&gt;
&lt;p&gt;This is my first blog post! Excited to get started. I've always wanted to have a nice, small blog where I can share my (albeit filtered) thoughts and ideas. My pitch that pretty much describes who I am and what I do is below.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I'm a passionate developer ‚Ä¶&lt;/p&gt;&lt;/blockquote&gt;</summary><content type="html">&lt;h1&gt;The beginning!&lt;/h1&gt;
&lt;p&gt;This is my first blog post! Excited to get started. I've always wanted to have a nice, small blog where I can share my (albeit filtered) thoughts and ideas. My pitch that pretty much describes who I am and what I do is below.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I'm a passionate developer with a knack for solving problems! My experience across Expedia Group, Microsoft, and Walmart has made me a versatile developer, comfortable in backend, frontend, fullstack, and even cloud engineering. I code in languages like Java, Python, and C++, and I'm well-versed in frameworks like Spring Boot and React. Plus, I hold certifications in Azure cloud architecture, making me a strong asset for any team looking to build and innovate. I like to tinker and try things out during my free time. I have a raspberry pi that I put to use often and several ideas that I try to execute when curiosity strikes.&lt;/p&gt;
&lt;/blockquote&gt;</content><category term="Blogging"></category></entry></feed>